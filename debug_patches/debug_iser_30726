commit eefbea135bbe42b55721e29b2a9eb18eca0a578d
Author: Potnuri Bharat Teja <bharat@chelsio.com>
Date:   Mon Aug 8 19:48:22 2016 +0530

    Debugging
    
    Signed-off-by: Potnuri Bharat Teja <bharat@chelsio.com>

diff --git a/Makefile b/Makefile
index 35603556023e..0540977304dc 100644
--- a/Makefile
+++ b/Makefile
@@ -1,7 +1,7 @@
 VERSION = 4
 PATCHLEVEL = 7
 SUBLEVEL = 0
-EXTRAVERSION =
+EXTRAVERSION = -rc7-for-iser
 NAME = Psychotic Stoned Sheep
 
 # *DOCUMENTATION*
diff --git a/drivers/infiniband/core/cma.c b/drivers/infiniband/core/cma.c
index e6dfa1bd3def..b410a0592d4e 100644
--- a/drivers/infiniband/core/cma.c
+++ b/drivers/infiniband/core/cma.c
@@ -3665,6 +3665,7 @@ int rdma_disconnect(struct rdma_cm_id *id)
 		if (ib_send_cm_dreq(id_priv->cm_id.ib, NULL, 0))
 			ib_send_cm_drep(id_priv->cm_id.ib, NULL, 0);
 	} else if (rdma_cap_iw_cm(id->device, id->port_num)) {
+		printk(KERN_ERR "##### rdma_disconnect #####\n");
 		ret = iw_cm_disconnect(id_priv->cm_id.iw, 0);
 	} else
 		ret = -EINVAL;
diff --git a/drivers/infiniband/core/iwcm.c b/drivers/infiniband/core/iwcm.c
index 357624f8b9d3..76fa2d90a24a 100644
--- a/drivers/infiniband/core/iwcm.c
+++ b/drivers/infiniband/core/iwcm.c
@@ -293,6 +293,7 @@ int iw_cm_disconnect(struct iw_cm_id *cm_id, int abrupt)
 		   !test_bit(IWCM_F_CONNECT_WAIT, &cm_id_priv->flags));
 
 	spin_lock_irqsave(&cm_id_priv->lock, flags);
+	printk(KERN_ERR "#####   iw_cm_disconnect  cm_id_priv->state  %d \n", cm_id_priv->state);
 	switch (cm_id_priv->state) {
 	case IW_CM_STATE_ESTABLISHED:
 		cm_id_priv->state = IW_CM_STATE_CLOSING;
@@ -325,10 +326,13 @@ int iw_cm_disconnect(struct iw_cm_id *cm_id, int abrupt)
 	spin_unlock_irqrestore(&cm_id_priv->lock, flags);
 
 	if (qp) {
-		if (abrupt)
+		if (abrupt) {
+			printk(KERN_ALERT "####### iw_cm_disconnect() abrupt #######\n");
 			ret = iwcm_modify_qp_err(qp);
-		else
+		} else {
+			printk(KERN_ALERT "####### iw_cm_disconnect() no abrupt #######\n");
 			ret = iwcm_modify_qp_sqd(qp);
+		}
 
 		/*
 		 * If both sides are disconnecting the QP could
diff --git a/drivers/infiniband/hw/cxgb4/cq.c b/drivers/infiniband/hw/cxgb4/cq.c
index 812ab7278b8e..a99ede17dec6 100644
--- a/drivers/infiniband/hw/cxgb4/cq.c
+++ b/drivers/infiniband/hw/cxgb4/cq.c
@@ -518,8 +518,10 @@ static int poll_cq(struct t4_wq *wq, struct t4_cq *cq, struct t4_cqe *cqe,
 		 * then drop
 		 */
 		if (CQE_TYPE(hw_cqe) == 1) {
-			if (CQE_STATUS(hw_cqe))
+			if (CQE_STATUS(hw_cqe)) {
+				printk(KERN_ERR "$$$$$ t4_set_wq_in_error 1 $$$$$\n");
 				t4_set_wq_in_error(wq);
+			}
 			ret = -EAGAIN;
 			goto skip_cqe;
 		}
@@ -529,8 +531,10 @@ static int poll_cq(struct t4_wq *wq, struct t4_cq *cq, struct t4_cqe *cqe,
 		 * connection setup.  So ignore the completion.
 		 */
 		if (CQE_WRID_STAG(hw_cqe) == 1) {
-			if (CQE_STATUS(hw_cqe))
+			if (CQE_STATUS(hw_cqe)) {
+				printk(KERN_ERR "$$$$$ t4_set_wq_in_error 2 $$$$$\n");
 				t4_set_wq_in_error(wq);
+			}
 			ret = -EAGAIN;
 			goto skip_cqe;
 		}
@@ -555,6 +559,7 @@ static int poll_cq(struct t4_wq *wq, struct t4_cq *cq, struct t4_cqe *cqe,
 
 	if (CQE_STATUS(hw_cqe) || t4_wq_in_error(wq)) {
 		*cqe_flushed = (CQE_STATUS(hw_cqe) == T4_ERR_SWFLUSH);
+		printk(KERN_ERR "$$$$$ t4_set_wq_in_error 3 $$$$$\n");
 		t4_set_wq_in_error(wq);
 	}
 
@@ -571,11 +576,13 @@ static int poll_cq(struct t4_wq *wq, struct t4_cq *cq, struct t4_cqe *cqe,
 		 */
 
 		if (t4_rq_empty(wq)) {
+			printk(KERN_ERR "$$$$$ t4_set_wq_in_error 4 $$$$$\n");
 			t4_set_wq_in_error(wq);
 			ret = -EAGAIN;
 			goto skip_cqe;
 		}
 		if (unlikely((CQE_WRID_MSN(hw_cqe) != (wq->rq.msn)))) {
+			printk(KERN_ERR "$$$$$ t4_set_wq_in_error 5 $$$$$\n");
 			t4_set_wq_in_error(wq);
 			hw_cqe->header |= htonl(CQE_STATUS_V(T4_ERR_MSN));
 			goto proc_cqe;
diff --git a/drivers/infiniband/hw/cxgb4/qp.c b/drivers/infiniband/hw/cxgb4/qp.c
index edb1172b6f54..480e16f3329d 100644
--- a/drivers/infiniband/hw/cxgb4/qp.c
+++ b/drivers/infiniband/hw/cxgb4/qp.c
@@ -761,16 +761,19 @@ int c4iw_post_send(struct ib_qp *ibqp, struct ib_send_wr *wr,
 	qhp = to_c4iw_qp(ibqp);
 	spin_lock_irqsave(&qhp->lock, flag);
 	if (t4_wq_in_error(&qhp->wq)) {
+		printk(KERN_ERR "$$$$$ t4_wq_in_error $$$$$\n");
 		spin_unlock_irqrestore(&qhp->lock, flag);
 		return -EINVAL;
 	}
 	num_wrs = t4_sq_avail(&qhp->wq);
 	if (num_wrs == 0) {
+		printk(KERN_ERR "$$$$$ t4_sq_avail 1 $$$$$\n");
 		spin_unlock_irqrestore(&qhp->lock, flag);
 		return -ENOMEM;
 	}
 	while (wr) {
 		if (num_wrs == 0) {
+			printk(KERN_ERR "$$$$$ t4_sq_avail 2 $$$$$\n");
 			err = -ENOMEM;
 			*bad_wr = wr;
 			break;
@@ -867,6 +870,7 @@ int c4iw_post_send(struct ib_qp *ibqp, struct ib_send_wr *wr,
 		spin_unlock_irqrestore(&qhp->lock, flag);
 		ring_kernel_sq_db(qhp, idx);
 	}
+	//printk(KERN_ERR "$$$$$ c4iw_post_send stat %d $$$$$\n", err);
 	return err;
 }
 
@@ -885,15 +889,18 @@ int c4iw_post_receive(struct ib_qp *ibqp, struct ib_recv_wr *wr,
 	spin_lock_irqsave(&qhp->lock, flag);
 	if (t4_wq_in_error(&qhp->wq)) {
 		spin_unlock_irqrestore(&qhp->lock, flag);
+		printk(KERN_ERR "$$$$ c4iw_post_receive t4_wq_in_error  $$$$$\n");
 		return -EINVAL;
 	}
 	num_wrs = t4_rq_avail(&qhp->wq);
 	if (num_wrs == 0) {
 		spin_unlock_irqrestore(&qhp->lock, flag);
+		printk(KERN_ERR "$$$$ c4iw_post_receive t4_rq_avail $$$$$\n");
 		return -ENOMEM;
 	}
 	while (wr) {
 		if (wr->num_sge > T4_MAX_RECV_SGE) {
+			printk(KERN_ERR "$$$$ c4iw_post_receive wr->num_sge > T4_MAX_RECV_SGE $$$$\n");
 			err = -EINVAL;
 			*bad_wr = wr;
 			break;
@@ -903,8 +910,10 @@ int c4iw_post_receive(struct ib_qp *ibqp, struct ib_recv_wr *wr,
 					   T4_EQ_ENTRY_SIZE);
 		if (num_wrs)
 			err = build_rdma_recv(qhp, wqe, wr, &len16);
-		else
+		else {
+			printk(KERN_ERR "$$$$ c4iw_post_receive num_wrs = 0 $$$$\n");
 			err = -ENOMEM;
+		}
 		if (err) {
 			*bad_wr = wr;
 			break;
@@ -1183,6 +1192,7 @@ static void flush_qp(struct c4iw_qp *qhp)
 	rchp = to_c4iw_cq(qhp->ibqp.recv_cq);
 	schp = to_c4iw_cq(qhp->ibqp.send_cq);
 
+	printk(KERN_ERR "$$$$$ t4_set_wq_in_error in flush_qp $$$$$\n");
 	t4_set_wq_in_error(&qhp->wq);
 	if (qhp->ibqp.uobject) {
 		t4_set_cq_in_error(&rchp->cq);
@@ -1450,6 +1460,7 @@ int c4iw_modify_qp(struct c4iw_dev *rhp, struct c4iw_qp *qhp,
 		switch (attrs->next_state) {
 		case C4IW_QP_STATE_CLOSING:
 			BUG_ON(atomic_read(&qhp->ep->com.kref.refcount) < 2);
+			printk(KERN_ERR "$$$$$ t4_set_wq_in_error modify 1 $$$$$\n");
 			t4_set_wq_in_error(&qhp->wq);
 			set_state(qhp, C4IW_QP_STATE_CLOSING);
 			ep = qhp->ep;
@@ -1463,6 +1474,7 @@ int c4iw_modify_qp(struct c4iw_dev *rhp, struct c4iw_qp *qhp,
 				goto err;
 			break;
 		case C4IW_QP_STATE_TERMINATE:
+			printk(KERN_ERR "$$$$$ t4_set_wq_in_error modify 2 $$$$$\n");
 			t4_set_wq_in_error(&qhp->wq);
 			set_state(qhp, C4IW_QP_STATE_TERMINATE);
 			qhp->attr.layer_etype = attrs->layer_etype;
@@ -1480,6 +1492,7 @@ int c4iw_modify_qp(struct c4iw_dev *rhp, struct c4iw_qp *qhp,
 			}
 			break;
 		case C4IW_QP_STATE_ERROR:
+			printk(KERN_ERR "$$$$$ t4_set_wq_in_error modify 3 $$$$$\n");
 			t4_set_wq_in_error(&qhp->wq);
 			set_state(qhp, C4IW_QP_STATE_ERROR);
 			if (!internal) {
@@ -1918,6 +1931,7 @@ void c4iw_drain_sq(struct ib_qp *ibqp)
 	unsigned long flag;
 	bool need_to_wait;
 
+	printk(KERN_ERR "\t\t\t\t## c4iw_drain_sq %p\n", qp);
 	move_qp_to_err(qp);
 	spin_lock_irqsave(&qp->lock, flag);
 	need_to_wait = !t4_sq_empty(&qp->wq);
@@ -1933,6 +1947,7 @@ void c4iw_drain_rq(struct ib_qp *ibqp)
 	unsigned long flag;
 	bool need_to_wait;
 
+	printk(KERN_ERR "\t\t\t\t## c4iw_drain_rq %p\n", qp);
 	move_qp_to_err(qp);
 	spin_lock_irqsave(&qp->lock, flag);
 	need_to_wait = !t4_rq_empty(&qp->wq);
diff --git a/drivers/infiniband/ulp/isert/ib_isert.c b/drivers/infiniband/ulp/isert/ib_isert.c
index ba6be060a476..ce6b86e872de 100644
--- a/drivers/infiniband/ulp/isert/ib_isert.c
+++ b/drivers/infiniband/ulp/isert/ib_isert.c
@@ -1808,6 +1808,7 @@ isert_put_response(struct iscsi_conn *conn, struct iscsi_cmd *cmd)
 	struct ib_send_wr *send_wr = &isert_cmd->tx_desc.send_wr;
 	struct iscsi_scsi_rsp *hdr = (struct iscsi_scsi_rsp *)
 				&isert_cmd->tx_desc.iscsi_header;
+	int ret;
 
 	isert_create_send_desc(isert_conn, isert_cmd, &isert_cmd->tx_desc);
 	iscsit_build_rsp_pdu(cmd, conn, true, hdr);
@@ -1846,7 +1847,10 @@ isert_put_response(struct iscsi_conn *conn, struct iscsi_cmd *cmd)
 
 	isert_dbg("Posting SCSI Response\n");
 
-	return isert_post_response(isert_conn, isert_cmd);
+	ret = isert_post_response(isert_conn, isert_cmd);
+	if (ret)
+		target_put_sess_cmd(&cmd->se_cmd);
+	return 0;
 }
 
 static void
@@ -2126,7 +2130,7 @@ isert_put_datain(struct iscsi_conn *conn, struct iscsi_cmd *cmd)
 	struct isert_conn *isert_conn = conn->context;
 	struct ib_cqe *cqe = NULL;
 	struct ib_send_wr *chain_wr = NULL;
-	int rc;
+	int ret;
 
 	isert_dbg("Cmd: %p RDMA_WRITE data_length: %u\n",
 		 isert_cmd, se_cmd->data_length);
@@ -2146,34 +2150,40 @@ isert_put_datain(struct iscsi_conn *conn, struct iscsi_cmd *cmd)
 		isert_init_send_wr(isert_conn, isert_cmd,
 				   &isert_cmd->tx_desc.send_wr);
 
-		rc = isert_post_recv(isert_conn, isert_cmd->rx_desc);
-		if (rc) {
-			isert_err("ib_post_recv failed with %d\n", rc);
-			return rc;
+		ret = isert_post_recv(isert_conn, isert_cmd->rx_desc);
+		if (ret) {
+			isert_err("ib_post_recv failed with %d\n", ret);
+			goto out;
 		}
 
 		chain_wr = &isert_cmd->tx_desc.send_wr;
 	}
 
-	isert_rdma_rw_ctx_post(isert_cmd, isert_conn, cqe, chain_wr);
+	ret = isert_rdma_rw_ctx_post(isert_cmd, isert_conn, cqe, chain_wr);
 	isert_dbg("Cmd: %p posted RDMA_WRITE for iSER Data READ\n", isert_cmd);
-	return 1;
+out:
+	if (ret)
+		target_put_sess_cmd(&cmd->se_cmd);
+	return 0;
 }
 
 static int
 isert_get_dataout(struct iscsi_conn *conn, struct iscsi_cmd *cmd, bool recovery)
 {
 	struct isert_cmd *isert_cmd = iscsit_priv_cmd(cmd);
+	int ret;
 
 	isert_dbg("Cmd: %p RDMA_READ data_length: %u write_data_done: %u\n",
 		 isert_cmd, cmd->se_cmd.data_length, cmd->write_data_done);
 
 	isert_cmd->tx_desc.tx_cqe.done = isert_rdma_read_done;
-	isert_rdma_rw_ctx_post(isert_cmd, conn->context,
+	ret = isert_rdma_rw_ctx_post(isert_cmd, conn->context,
 			&isert_cmd->tx_desc.tx_cqe, NULL);
 
 	isert_dbg("Cmd: %p posted RDMA_READ memory for ISER Data WRITE\n",
 		 isert_cmd);
+	if (ret)
+		target_put_sess_cmd(&cmd->se_cmd);
 	return 0;
 }
 
diff --git a/drivers/scsi/scsi_transport_iscsi.c b/drivers/scsi/scsi_transport_iscsi.c
index 42bca619f854..1ecd7fe166c0 100644
--- a/drivers/scsi/scsi_transport_iscsi.c
+++ b/drivers/scsi/scsi_transport_iscsi.c
@@ -2867,6 +2867,7 @@ iscsi_if_transport_ep(struct iscsi_transport *transport,
 	switch (msg_type) {
 	case ISCSI_UEVENT_TRANSPORT_EP_CONNECT_THROUGH_HOST:
 	case ISCSI_UEVENT_TRANSPORT_EP_CONNECT:
+		printk(KERN_ERR "#### iscsi_if_ep_connect  #####\n");
 		rc = iscsi_if_ep_connect(transport, ev, msg_type);
 		break;
 	case ISCSI_UEVENT_TRANSPORT_EP_POLL:
diff --git a/drivers/target/iscsi/Makefile b/drivers/target/iscsi/Makefile
index 0f18295e05bc..359d6239d59d 100644
--- a/drivers/target/iscsi/Makefile
+++ b/drivers/target/iscsi/Makefile
@@ -1,3 +1,22 @@
+CFLAGS_iscsi_target_parameters.o := -DDEBUG
+CFLAGS_iscsi_target_seq_pdu_list.o := -DDEBUG
+CFLAGS_iscsi_target_auth.o := -DDEBUG
+CFLAGS_iscsi_target_datain_values.o := -DDEBUG
+CFLAGS_iscsi_target_device.o := -DDEBUG
+CFLAGS_iscsi_target_erl0.o := -DDEBUG
+CFLAGS_iscsi_target_erl1.o := -DDEBUG
+CFLAGS_iscsi_target_erl2.o := -DDEBUG
+CFLAGS_iscsi_target_login.o := -DDEBUG
+CFLAGS_iscsi_target_nego.o := -DDEBUG
+CFLAGS_iscsi_target_nodeattrib.o := -DDEBUG
+CFLAGS_iscsi_target_tmr.o := -DDEBUG
+CFLAGS_iscsi_target_tpg.o := -DDEBUG
+CFLAGS_iscsi_target_util.o := -DDEBUG
+CFLAGS_iscsi_target.o := -DDEBUG
+CFLAGS_iscsi_target_configfs.o := -DDEBUG
+CFLAGS_iscsi_target_stat.o := -DDEBUG
+CFLAGS_iscsi_target_transport.o := -DDEBUG
+
 iscsi_target_mod-y +=		iscsi_target_parameters.o \
 				iscsi_target_seq_pdu_list.o \
 				iscsi_target_auth.o \
diff --git a/drivers/target/target_core_transport.c b/drivers/target/target_core_transport.c
index 6094a6beddde..719d7ef7292f 100644
--- a/drivers/target/target_core_transport.c
+++ b/drivers/target/target_core_transport.c
@@ -2552,6 +2552,7 @@ int target_get_sess_cmd(struct se_cmd *se_cmd, bool ack_kref)
 
 	spin_lock_irqsave(&se_sess->sess_cmd_lock, flags);
 	if (se_sess->sess_tearing_down) {
+		printk("\t\t\t\t ******** tearing down  se_sess->sess_tearing_down ********\n");
 		ret = -ESHUTDOWN;
 		goto out;
 	}
@@ -2591,6 +2592,7 @@ static void target_release_cmd_kref(struct kref *kref)
 	spin_unlock(&se_cmd->t_state_lock);
 
 	if (se_cmd->cmd_wait_set || fabric_stop) {
+		printk(KERN_ERR "$$$$$ inside If() $$$$$\n");
 		list_del_init(&se_cmd->se_cmd_list);
 		spin_unlock_irqrestore(&se_sess->sess_cmd_lock, flags);
 		target_free_cmd_mem(se_cmd);
@@ -2673,8 +2675,10 @@ void target_wait_for_sess_cmds(struct se_session *se_sess)
 		spin_unlock_irqrestore(&se_cmd->t_state_lock, flags);
 
 		if (!target_put_sess_cmd(se_cmd)) {
-			if (tas)
+			if (tas) {
 				target_put_sess_cmd(se_cmd);
+				printk(KERN_ERR "\t\t\t#### put is set ####\n");
+			}
 		}
 
 		wait_for_completion(&se_cmd->cmd_wait_comp);
