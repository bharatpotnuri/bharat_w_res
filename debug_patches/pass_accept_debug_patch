diff -r ce631b5d76cc dev/T4/linux/drv/l2t.c
--- a/dev/T4/linux/drv/l2t.c	Wed Nov 25 11:18:25 2015 +0530
+++ b/dev/T4/linux/drv/l2t.c	Wed Nov 25 19:50:50 2015 +0530
@@ -403,6 +403,113 @@ again:
 }
 EXPORT_SYMBOL(cxgb4_l2t_send);
 
+int cxgb4_l2t_send1(struct net_device *dev, struct sk_buff *skb,
+		   struct l2t_entry *e, struct sock *sk, int force)
+{
+	struct adapter *adap = netdev2adap(dev);
+	struct sk_buff *skb_ndisc = NULL;
+#if defined(CONFIG_TCPV6_OFFLOAD)
+	struct in6_addr addr_buf;
+	struct icmp6hdr icmp6h = {
+		.icmp6_type = NDISC_NEIGHBOUR_SOLICITATION,
+	};
+	struct in6_addr *target = (struct in6_addr *)&e->addr;
+	struct net_device *ndev = dev;
+
+	/* Get the vlan interface, later used to build the skb
+	 */
+	if (e->neigh && is_vlan_dev(e->neigh->dev))
+		ndev = e->neigh->dev;
+#endif
+	/*
+	if (force == 1) {
+		printk(KERN_ALERT "############# %s ##########\n", __func__);
+		spin_lock_bh(&e->lock);
+		arpq_enqueue(e, skb);
+		spin_unlock_bh(&e->lock);
+	}
+	*/
+	
+	printk(KERN_ALERT "############# %s e->state %d ##########\n", __func__, e->state);
+again:
+	e->state = L2T_STATE_NOARP;
+	switch (e->state) {
+	case L2T_STATE_STALE:     /* entry is stale, kick off revalidation */
+#if defined(CONFIG_TCPV6_OFFLOAD)
+		/* PR15808: When IPv6 link local address is removed,
+		 * neighbour discovery fails as ndisc_solicit->ndisc_send_ns
+		 * looks for link local address to send NEIGHBOUR_SOLICITATION
+		 * packet. Here we are generating the NEIGHBOUR_SOLICITATION
+		 * packet with the correct source address.
+		 */
+		if (e->v6 && chelsio_ipv6_get_lladdr(ndev, &addr_buf,
+				(IFA_F_TENTATIVE|IFA_F_OPTIMISTIC))) {
+			skb_ndisc = ndisc_build_skb(ndev, target,
+						    &inet6_sk_rcv_saddr(sk),
+						    &icmp6h, target, 0);
+			if (skb_ndisc && !skb_dst(skb_ndisc))
+				skb_dst_set(skb_ndisc, dst_clone(__sk_dst_get(sk)));
+		}
+#endif
+		neigh_event_send(e->neigh, skb_ndisc);
+		spin_lock_bh(&e->lock);
+		if (e->state == L2T_STATE_STALE)
+			e->state = L2T_STATE_VALID;
+		spin_unlock_bh(&e->lock);
+	case L2T_STATE_VALID:     /* fast-path, send the packet on */
+		return t4_ofld_send(adap, skb);
+	case L2T_STATE_NOARP:
+		spin_lock_bh(&e->lock);
+		printk(KERN_ALERT "############# %s ##########\n", __func__);
+		arpq_enqueue(e, skb);
+		spin_unlock_bh(&e->lock);
+		break;
+	case L2T_STATE_RESOLVING:
+	case L2T_STATE_SYNC_WRITE:
+		spin_lock_bh(&e->lock);
+		if (e->state != L2T_STATE_SYNC_WRITE &&
+		    e->state != L2T_STATE_RESOLVING) {
+			/* ARP already completed */
+			spin_unlock_bh(&e->lock);
+			goto again;
+		}
+		arpq_enqueue(e, skb);
+		spin_unlock_bh(&e->lock);
+
+		/*
+		 * Only the first packet added to the arpq should kick off
+		 * resolution.  However, because skb allocation can fail,
+		 * we allow each packet added to the arpq to retry resolution
+		 * as a way of recovering from transient memory exhaustion.
+		 * A better way would be to use a work request to retry L2T
+		 * entries when there's no memory.
+		 */
+		if (e->state == L2T_STATE_RESOLVING) {
+#if defined(CONFIG_TCPV6_OFFLOAD)
+			if (e->v6 && chelsio_ipv6_get_lladdr(ndev, &addr_buf,
+					(IFA_F_TENTATIVE|IFA_F_OPTIMISTIC))) {
+				skb_ndisc = ndisc_build_skb(ndev, target,
+							    &inet6_sk_rcv_saddr(sk),
+							    &icmp6h, target, 0);
+				if (skb_ndisc && !skb_dst(skb_ndisc))
+					skb_dst_set(skb_ndisc, dst_clone(__sk_dst_get(sk)));
+			}
+#endif
+			if (e->neigh &&
+				!neigh_event_send(e->neigh, skb_ndisc)) {
+				spin_lock_bh(&e->lock);
+				if (e->state == L2T_STATE_RESOLVING &&
+					!skb_queue_empty(&e->arpq))
+						write_l2e(adap, e, 1,
+						      !L2T_LPBK, !L2T_ARPMISS);
+				spin_unlock_bh(&e->lock);
+			}
+		}
+	}
+	return 0;
+}
+EXPORT_SYMBOL(cxgb4_l2t_send1);
+
 /*
  * Allocate a free L2T entry.  Must be called with l2t_data.lock held.
  */
@@ -1088,9 +1195,17 @@ struct l2t_data *t4_init_l2t(unsigned in
 static void flush_arpq(struct l2t_entry *e)
 {
 	struct sk_buff *skb;
+	printk(KERN_ALERT "############# %s 1 ##########\n", __func__);
 
-	while ((skb = __skb_dequeue(&e->arpq)) != NULL)
-		kfree_skb(skb);
+	while ((skb = __skb_dequeue(&e->arpq)) != NULL) {
+		struct l2t_skb_cb *cb = L2T_SKB_CB(skb);
+		if (cb->arp_err_handler) {
+			printk(KERN_ALERT "############# %s 2 ##########\n", __func__);
+			cb->arp_err_handler(cb->handle, skb);
+		} else {
+			kfree_skb(skb);
+		}
+	}
 }
 
 /*
@@ -1101,15 +1216,17 @@ static void flush_arpq(struct l2t_entry 
 void t4_flush_l2t_arpq(struct l2t_data *d)
 {
 	int i;
-
+	printk(KERN_ALERT "############# %s ##########\n", __func__);
 	read_lock_bh(&d->lock);
 	for (i = 0; i < d->l2t_size; ++i) {
 		struct l2t_entry *e;
 
 		e = &d->l2tab[i];
 		spin_lock(&e->lock);
-		if (!skb_queue_empty(&e->arpq))
+		if (!skb_queue_empty(&e->arpq)) {
+			printk(KERN_ALERT "############# %s ##########\n", __func__);
 			flush_arpq(e);
+		}
 		spin_unlock(&e->lock);
 	}
 	read_unlock_bh(&d->lock);
@@ -1206,6 +1323,8 @@ static int l2t_seq_open(struct inode *in
 		struct seq_file *seq = file->private_data;
 
 		seq->private = adap->l2t;
+		printk(KERN_ALERT "############# %s ##########\n", __func__);
+		t4_flush_l2t_arpq(adap->l2t);
 	}
 	return rc;
 }
diff -r ce631b5d76cc dev/T4/linux/drv/l2t.h
--- a/dev/T4/linux/drv/l2t.h	Wed Nov 25 11:18:25 2015 +0530
+++ b/dev/T4/linux/drv/l2t.h	Wed Nov 25 19:50:50 2015 +0530
@@ -109,6 +109,8 @@ static inline unsigned int t4_l2t_check_
 void cxgb4_l2t_release(struct l2t_entry *e);
 int cxgb4_l2t_send(struct net_device *dev, struct sk_buff *skb,
 		   struct l2t_entry *e, struct sock *sk);
+int cxgb4_l2t_send1(struct net_device *dev, struct sk_buff *skb,
+		   struct l2t_entry *e, struct sock *sk, int force);
 struct l2t_entry *cxgb4_l2t_get(struct l2t_data *d, struct neighbour *neigh,
 				const struct net_device *physdev , u32 priority);
 struct l2t_entry *cxgb4_l2t_alloc_switching(struct net_device *dev, u16 vlan,
diff -r ce631b5d76cc dev/T4/linux/iw_cxgb4/cm.c
--- a/dev/T4/linux/iw_cxgb4/cm.c	Wed Nov 25 11:18:25 2015 +0530
+++ b/dev/T4/linux/iw_cxgb4/cm.c	Wed Nov 25 19:50:50 2015 +0530
@@ -234,6 +234,25 @@ static int c4iw_l2t_send(struct c4iw_rde
 	return error < 0 ? error : 0;
 }
 
+static int c4iw_l2t_send1(struct c4iw_rdev *rdev, struct sk_buff *skb,
+		  struct l2t_entry *l2e)
+{
+	int	error = 0;
+	
+	printk(KERN_ALERT "############# %s ##########\n", __func__);
+	if (c4iw_fatal_error(rdev)) {
+		kfree_skb(skb);
+		PDBG("%s - device in error state - dropping\n", __func__);
+		return -EIO;
+	}
+	error = cxgb4_l2t_send1(rdev->lldi.ports[0], skb, l2e, NULL,1);
+	if (error < 0)
+		kfree_skb(skb);
+	else if (error == NET_XMIT_DROP)
+		return -ENOMEM;
+	return error < 0 ? error : 0;
+}
+
 int c4iw_ofld_send(struct c4iw_rdev *rdev, struct sk_buff *skb)
 {
 	int	error = 0;
@@ -606,6 +625,9 @@ static void pass_accept_rpl_arp_failure(
 	struct c4iw_ep *ep = handle;
 
 	printk(KERN_ERR MOD "ARP failure during accept - tid %u - dropping connection\n", ep->hwtid);
+	printk(KERN_ALERT "############# %s ##########\n", __func__);
+	printk(KERN_ALERT "############# YES!!! I AM HIT!! FINALLY!  ##########\n");
+
 	__state_set(&ep->com, DEAD);
 	queue_arp_failure_cpl(ep, skb);
 }
@@ -2595,6 +2617,8 @@ static int accept_cr(struct c4iw_ep *ep,
 	struct cpl_pass_accept_rpl *rpl;
 	unsigned int mtu_idx;
 	u64 opt0;
+	u64 cnt1 = 0xffffffff;
+	u64 cnt2 = 0;
 	u32 opt2;
 	int wscale;
 	int win;
@@ -2690,7 +2714,7 @@ static int accept_cr(struct c4iw_ep *ep,
 	rpl->opt2 = cpu_to_be32(opt2);
 	set_wr_txq(skb, CPL_PRIORITY_SETUP, ep->ctrlq_idx);
 	t4_set_arp_err_handler(skb, ep, pass_accept_rpl_arp_failure);
-	return c4iw_l2t_send(&ep->com.dev->rdev, skb, ep->l2t);
+	return c4iw_l2t_send1(&ep->com.dev->rdev, skb, ep->l2t);
 }
 
 static void reject_cr(struct c4iw_dev *dev, u32 hwtid, struct sk_buff *skb)
@@ -2791,8 +2815,8 @@ static int pass_accept_req(struct c4iw_d
 	/* Find output route */
 #ifdef IWARP_IPV6_SUPPORT
 	if (iptype == 4)  {
-		PDBG("%s parent ep %p hwtid %u laddr %pI4 raddr %pI4 lport\n"
-		     "%d rport %d peer_mss %d\n", __func__, parent_ep, hwtid,
+		PDBG("%s parent ep %p parent parent ep %p hwtid %u laddr %pI4 raddr %pI4 lport\n"
+		     "%d rport %d peer_mss %d\n", __func__, parent_ep, parent_ep->parent_ep, hwtid,
 		     local_ip, peer_ip, ntohs(local_port),
 		     ntohs(peer_port), peer_mss);
 		dst = find_route(dev, *(__be32 *)local_ip, *(__be32 *)peer_ip,
@@ -2809,8 +2833,8 @@ static int pass_accept_req(struct c4iw_d
 				   com.local_addr)->sin6_scope_id);
 	}
 #else
-	PDBG("%s parent ep %p hwtid %u laddr %pI4 raddr %pI4 lport\n"
-	     "%d rport %d peer_mss %d\n", __func__, parent_ep, hwtid,
+	PDBG("%s parent ep %p parent parent ep %p hwtid %u laddr %pI4 raddr %pI4 lport\n"
+	     "%d rport %d peer_mss %d\n", __func__, parent_ep, parent_ep->parent_ep, hwtid,
 	     local_ip, peer_ip, ntohs(local_port), ntohs(peer_port), peer_mss);
 	dst = find_route(dev, *(__be32 *)local_ip, *(__be32 *)peer_ip,
 			 local_port, peer_port,
